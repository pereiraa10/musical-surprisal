{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0676d20b",
   "metadata": {},
   "source": [
    "# How to run IDyOMpy and codeForPaper\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b51021f",
   "metadata": {},
   "source": [
    "#### Create a new conda environment and activate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b64c28f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "conda create -n idyompyenv\n",
    "conda activate idyompyenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24f9d67",
   "metadata": {},
   "source": [
    "#### Get the code_for_paper repo from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0256a2a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "git clone https://github.com/GuiMarion/codeForPaper-IDyOMpy-.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2dedae",
   "metadata": {},
   "source": [
    "#### Navigate inside the \"codeForPaper-IDyOMpy\" and clone the original IDyOM repo and navigate inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7bf6d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cd codeForPaper-IDyOMpy\n",
    "git clone https://github.com/GuiMarion/IDyOM.git\n",
    "cd IDyOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d21c0",
   "metadata": {},
   "source": [
    "#### Make a virtual environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62175b9e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "python3 -m venv .venv\n",
    "source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c171e6d7",
   "metadata": {},
   "source": [
    "#### Install the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd476c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027ca901",
   "metadata": {},
   "source": [
    "## Run Bash Scripts for Benchmark plots\n",
    "\n",
    "#### Copy over the relevant bash script inside of the IDyOM folder. Then make a text file to save the terminal output into so you can check for errors later. (I named mine \"bm_IDyOMpy_PPM.txt\")\n",
    "\n",
    "#### From inside IDyOMpy, make the bash script executable (replace bash script name as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0585129b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "chmod +x run_for_benchmark_IDyOMpy.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18b907",
   "metadata": {},
   "source": [
    "#### Make sure your virtual environments are activated, and then run the bash script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c7cb86",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "./run_for_benchmark_IDyOMpy.sh 2>&1 | tee bm_IDyOMpy_PPM.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaabda0",
   "metadata": {},
   "source": [
    "run_for_benchmark_IDyOMpy\n",
    "- started at 3:31 pm Dec 10th\n",
    "- finished at 3:49 pm Dec 10th\n",
    "\n",
    "run_for_benchmark_IDyOMpy_PPM (run consecutively)\n",
    "- started at 3:52 pm Dec 10th \n",
    "- early termination\n",
    "- results saved in bm_IDyOMpy_PPM.txt\n",
    "\n",
    "run_for_benchmark_IDyOMpy_Genuine (run after re-cloning a new repo from scratch)\n",
    "- started at 5:05 pm Dec 10th\n",
    "- early termination at 7:05 pm Dec 10th \n",
    "- results saved in benchmark_GE.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b3c54e",
   "metadata": {},
   "source": [
    "### Notes on running:\n",
    "\n",
    "If you need to restart, delete the IDyOM folder within the codeForPaper repo, delete the benchmark results folder as well, then restart from cloning in the new IDyOM repo. A folder called .TEMP and out are created during this Bash script. \n",
    "\n",
    "PPM model bash script checks for an additional 3 models (.._originalPPM) to be deleted if present.  \n",
    "\n",
    "#### Running the actual python files\n",
    "\n",
    "\n",
    "**IDyOM_AE** file runs App.py -t (TRAIN_FOLDER) and -s (TRIAL_FOLDER) what surprisal is calculated on:\n",
    "| -t (Train)             | -s (Calc Surprisal)    |\n",
    "|------------------------|------------------------|\n",
    "| train_shanxi (Chinese) | bach_Pearce            |\n",
    "| bach_Pearce (Bach)     | train_shanxi           |\n",
    "| mixed2 (Large Western) | stimuli/GregoireMcGill |\n",
    "\n",
    "\n",
    "Then file computes cross entropy of the bach_Pearce folder while also running App.py on these combinations of training / surprisal validation:\n",
    "| -t (Train)             | -s (Calc Surprisal)    |\n",
    "|------------------------|------------------------|\n",
    "| mixed2 (Large Western) | stimuli/giovanni /          |\n",
    "| mixed2 (Large Western) | stimuli/Gold/        |\n",
    "| bach_Pearce (Bach)  | stimuli/GregoireMcGill |\n",
    "| bach_Pearce (Bach)  | stimuli/giovanni /          |\n",
    "\n",
    "\n",
    "Also then calls -e on the bach_Pearson folder, which trains and evaluates over training, but does just -c cross entropy calculation for train_shanxi and mixed2. \n",
    "\n",
    "These scripts print and save alot of results, which are then copied from the \"out\" folder into the benchmark_results folder. \n",
    "\n",
    "\n",
    "**IDyOM_PPM** does a nearly similar set of actions, except it adds -o 1 to each line meaning to use the Partial Pattern Matching function from the original Lisp implementation. \n",
    "\n",
    "It also upfront starts to calc the cross entropy of all 3 datasets, bach_Pearce, train_shanxi, and mixed2 with -o 1 while training the same 4  combination of datasets and validations above. \n",
    "\n",
    "Once that's all done, it copies the values from out folder into the benchmark results\n",
    "\n",
    "**IDyOM_GE** has the same exact set up but with -g instead of -o everywhere. This is noted to be 5 times slower than the original file which makes sense based on my latest experiments, but I havent been able to get the job to fully finish. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3906b3",
   "metadata": {},
   "source": [
    "## Looking at the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1716b3b7",
   "metadata": {},
   "source": [
    "In the newly created \"benchmark_results\" folder located above the IDyOM folder, you will see the \"likelihoods_cross_eval_k_fold_5_quantization_24_maxOrder_20_viewpoints_pitch_length\" results in matplot and in pickle form for each of the datasets trained on.\n",
    "\n",
    "In matplot, you will unpack multiple variables each corresponds to a song. For each song you have the Information Content (generalization error) as the first dimension, and then the Relative Entropy as the second dimension. They are both vectors over the time dimension. These measures relate to the surprisal we are seeing. \n",
    "\n",
    "## Open Questions:\n",
    "- How do we group together results for the mean generalization error (IC) values in the chart? is this over time first in the song, then across songs?\n",
    "- Why does IDyOM_GE and PPM not finish running but the other one does? \n",
    "\n",
    "## Things to try next:\n",
    "- Comment out all versions of results we don't need and see if we can just run once on the dataset \n",
    "- Read the Bash script thoroughly and convert it to a customizable Python script including printing the terminal results into a text file (or add this to the bash code??)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
